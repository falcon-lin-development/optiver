{
 "cells": [
  {
   "cell_type": "raw",
   "id": "db3b66f8",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.006165,
     "end_time": "2023-10-13T14:22:59.150820",
     "exception": false,
     "start_time": "2023-10-13T14:22:59.144655",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8541ee9",
   "metadata": {
    "papermill": {
     "duration": 0.005466,
     "end_time": "2023-10-13T14:22:59.161716",
     "exception": false,
     "start_time": "2023-10-13T14:22:59.156250",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Section 1: Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62effb5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T14:22:59.175549Z",
     "iopub.status.busy": "2023-10-13T14:22:59.175206Z",
     "iopub.status.idle": "2023-10-13T14:23:02.637032Z",
     "shell.execute_reply": "2023-10-13T14:23:02.636051Z"
    },
    "papermill": {
     "duration": 3.471996,
     "end_time": "2023-10-13T14:23:02.639388",
     "exception": false,
     "start_time": "2023-10-13T14:22:59.167392",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a30721cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T14:23:02.651946Z",
     "iopub.status.busy": "2023-10-13T14:23:02.651593Z",
     "iopub.status.idle": "2023-10-13T14:23:03.465928Z",
     "shell.execute_reply": "2023-10-13T14:23:03.464970Z"
    },
    "papermill": {
     "duration": 0.8227,
     "end_time": "2023-10-13T14:23:03.468051",
     "exception": false,
     "start_time": "2023-10-13T14:23:02.645351",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# import lightgbm as lgb\n",
    "import gc\n",
    "import sys\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from warnings import simplefilter\n",
    "simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d765402",
   "metadata": {
    "papermill": {
     "duration": 0.005703,
     "end_time": "2023-10-13T14:23:03.480682",
     "exception": false,
     "start_time": "2023-10-13T14:23:03.474979",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Section 2: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26967b8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T14:23:03.492452Z",
     "iopub.status.busy": "2023-10-13T14:23:03.492045Z",
     "iopub.status.idle": "2023-10-13T14:23:20.122490Z",
     "shell.execute_reply": "2023-10-13T14:23:20.121442Z"
    },
    "papermill": {
     "duration": 16.638999,
     "end_time": "2023-10-13T14:23:20.124874",
     "exception": false,
     "start_time": "2023-10-13T14:23:03.485875",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('/kaggle/input/optiver-trading-at-the-close/train.csv')\n",
    "# revealed_targets = pd.read_csv('/kaggle/input/optiver-trading-at-the-close/example_test_files/revealed_targets.csv')\n",
    "test = pd.read_csv('/kaggle/input/optiver-trading-at-the-close/example_test_files/test.csv')\n",
    "# sample_submission = pd.read_csv('/kaggle/input/optiver-trading-at-the-close/example_test_files/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b21ba4b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T14:23:20.137330Z",
     "iopub.status.busy": "2023-10-13T14:23:20.136757Z",
     "iopub.status.idle": "2023-10-13T14:23:20.143673Z",
     "shell.execute_reply": "2023-10-13T14:23:20.142843Z"
    },
    "papermill": {
     "duration": 0.014967,
     "end_time": "2023-10-13T14:23:20.145437",
     "exception": false,
     "start_time": "2023-10-13T14:23:20.130470",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['stock_id', 'date_id', 'seconds_in_bucket', 'imbalance_size',\n",
       "       'imbalance_buy_sell_flag', 'reference_price', 'matched_size',\n",
       "       'far_price', 'near_price', 'bid_price', 'bid_size', 'ask_price',\n",
       "       'ask_size', 'wap', 'target', 'time_id', 'row_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e55dbe4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T14:23:20.157538Z",
     "iopub.status.busy": "2023-10-13T14:23:20.156830Z",
     "iopub.status.idle": "2023-10-13T14:23:20.162811Z",
     "shell.execute_reply": "2023-10-13T14:23:20.161899Z"
    },
    "papermill": {
     "duration": 0.01378,
     "end_time": "2023-10-13T14:23:20.164521",
     "exception": false,
     "start_time": "2023-10-13T14:23:20.150741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5237980, 17)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8ad1259",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T14:23:20.176637Z",
     "iopub.status.busy": "2023-10-13T14:23:20.175926Z",
     "iopub.status.idle": "2023-10-13T14:23:20.200271Z",
     "shell.execute_reply": "2023-10-13T14:23:20.199286Z"
    },
    "papermill": {
     "duration": 0.03234,
     "end_time": "2023-10-13T14:23:20.202077",
     "exception": false,
     "start_time": "2023-10-13T14:23:20.169737",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>date_id</th>\n",
       "      <th>seconds_in_bucket</th>\n",
       "      <th>imbalance_size</th>\n",
       "      <th>imbalance_buy_sell_flag</th>\n",
       "      <th>reference_price</th>\n",
       "      <th>matched_size</th>\n",
       "      <th>far_price</th>\n",
       "      <th>near_price</th>\n",
       "      <th>bid_price</th>\n",
       "      <th>bid_size</th>\n",
       "      <th>ask_price</th>\n",
       "      <th>ask_size</th>\n",
       "      <th>wap</th>\n",
       "      <th>target</th>\n",
       "      <th>time_id</th>\n",
       "      <th>row_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3180602.69</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>13380276.64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>60651.50</td>\n",
       "      <td>1.000026</td>\n",
       "      <td>8493.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.029704</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>166603.91</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>1642214.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>3233.04</td>\n",
       "      <td>1.000660</td>\n",
       "      <td>20605.09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.519986</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>302879.87</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999561</td>\n",
       "      <td>1819368.03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999403</td>\n",
       "      <td>37956.00</td>\n",
       "      <td>1.000298</td>\n",
       "      <td>18995.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-8.389950</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11917682.27</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000171</td>\n",
       "      <td>18389745.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>2324.90</td>\n",
       "      <td>1.000214</td>\n",
       "      <td>479032.40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.010200</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>447549.96</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999532</td>\n",
       "      <td>17860614.95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999394</td>\n",
       "      <td>16485.54</td>\n",
       "      <td>1.000016</td>\n",
       "      <td>434.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-7.349849</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0_4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stock_id  date_id  seconds_in_bucket  imbalance_size  \\\n",
       "0         0        0                  0      3180602.69   \n",
       "1         1        0                  0       166603.91   \n",
       "2         2        0                  0       302879.87   \n",
       "3         3        0                  0     11917682.27   \n",
       "4         4        0                  0       447549.96   \n",
       "\n",
       "   imbalance_buy_sell_flag  reference_price  matched_size  far_price  \\\n",
       "0                        1         0.999812   13380276.64        NaN   \n",
       "1                       -1         0.999896    1642214.25        NaN   \n",
       "2                       -1         0.999561    1819368.03        NaN   \n",
       "3                       -1         1.000171   18389745.62        NaN   \n",
       "4                       -1         0.999532   17860614.95        NaN   \n",
       "\n",
       "   near_price  bid_price  bid_size  ask_price   ask_size  wap    target  \\\n",
       "0         NaN   0.999812  60651.50   1.000026    8493.03  1.0 -3.029704   \n",
       "1         NaN   0.999896   3233.04   1.000660   20605.09  1.0 -5.519986   \n",
       "2         NaN   0.999403  37956.00   1.000298   18995.00  1.0 -8.389950   \n",
       "3         NaN   0.999999   2324.90   1.000214  479032.40  1.0 -4.010200   \n",
       "4         NaN   0.999394  16485.54   1.000016     434.10  1.0 -7.349849   \n",
       "\n",
       "   time_id row_id  \n",
       "0        0  0_0_0  \n",
       "1        0  0_0_1  \n",
       "2        0  0_0_2  \n",
       "3        0  0_0_3  \n",
       "4        0  0_0_4  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0711396f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T14:23:20.216376Z",
     "iopub.status.busy": "2023-10-13T14:23:20.216084Z",
     "iopub.status.idle": "2023-10-13T14:23:20.927465Z",
     "shell.execute_reply": "2023-10-13T14:23:20.926594Z"
    },
    "papermill": {
     "duration": 0.721635,
     "end_time": "2023-10-13T14:23:20.929322",
     "exception": false,
     "start_time": "2023-10-13T14:23:20.207687",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5237980, 17)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.fillna(1) # write nan to 1\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e39deac",
   "metadata": {
    "papermill": {
     "duration": 0.005911,
     "end_time": "2023-10-13T14:23:20.941460",
     "exception": false,
     "start_time": "2023-10-13T14:23:20.935549",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Section 2A: Feature Engineering\n",
    "> TODO: Feature Engin.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8116ef51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T14:23:20.954668Z",
     "iopub.status.busy": "2023-10-13T14:23:20.954078Z",
     "iopub.status.idle": "2023-10-13T14:23:20.960082Z",
     "shell.execute_reply": "2023-10-13T14:23:20.959292Z"
    },
    "papermill": {
     "duration": 0.01466,
     "end_time": "2023-10-13T14:23:20.961834",
     "exception": false,
     "start_time": "2023-10-13T14:23:20.947174",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def feat_eng(df):\n",
    "    cols = [c for c in df.columns if c not in ['row_id', 'time_id']] # compatible for training, test and inference\n",
    "    df = df[cols]\n",
    "    # feature_engineering\n",
    "    df.drop(columns=[\n",
    "        'date_id', \n",
    "#         'reference_price_far_price_imb',\n",
    "#         'reference_price_minus_near_price',\n",
    "#         'reference_price_near_price_imb',\n",
    "#         'far_price_near_price_imb',\n",
    "#         'far_price_ask_price_imb',\n",
    "#         'far_price_bid_price_imb',\n",
    "#         'far_price_minus_wap',\n",
    "#         'std_size',\n",
    "#         'bid_size_over_ask_size',\n",
    "#         'ask_price_bid_price_imb',\n",
    "#         'near_price_times_wap'\n",
    "    ], inplace=True)\n",
    "        \n",
    "    gc.collect()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a482e7d",
   "metadata": {
    "papermill": {
     "duration": 0.005712,
     "end_time": "2023-10-13T14:23:20.973243",
     "exception": false,
     "start_time": "2023-10-13T14:23:20.967531",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Section 2B: Ready X, y\n",
    "\n",
    "> TODO: train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54da234e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T14:23:20.986949Z",
     "iopub.status.busy": "2023-10-13T14:23:20.986073Z",
     "iopub.status.idle": "2023-10-13T14:23:22.858989Z",
     "shell.execute_reply": "2023-10-13T14:23:22.857701Z"
    },
    "papermill": {
     "duration": 1.881708,
     "end_time": "2023-10-13T14:23:22.861012",
     "exception": false,
     "start_time": "2023-10-13T14:23:20.979304",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.28 s, sys: 907 ms, total: 2.19 s\n",
      "Wall time: 1.87 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "y = train['target'].values\n",
    "X = feat_eng(train.drop(columns='target'))\n",
    "\n",
    "# normalization of data\n",
    "mean = X.mean(axis=0)\n",
    "std = X.std(axis=0)\n",
    "std[std == 0] = 1 # Avoid division by zero\n",
    "X = (X - mean) / std\n",
    "\n",
    "\n",
    "# y = y[:50000]\n",
    "# X = X[:50000]\n",
    "\n",
    "\n",
    "\n",
    "# prices = [c for c in train.columns if 'price' in c]\n",
    "# pca_prices = PCA(n_components=1)\n",
    "# X['pca_prices'] = pca_prices.fit_transform(X[prices].fillna(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ecc8c05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T14:23:22.874875Z",
     "iopub.status.busy": "2023-10-13T14:23:22.874111Z",
     "iopub.status.idle": "2023-10-13T14:23:22.881566Z",
     "shell.execute_reply": "2023-10-13T14:23:22.880618Z"
    },
    "papermill": {
     "duration": 0.015832,
     "end_time": "2023-10-13T14:23:22.883261",
     "exception": false,
     "start_time": "2023-10-13T14:23:22.867429",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5237980,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(5237980, 13)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(y.shape)\n",
    "display(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6676b704",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T14:23:22.895950Z",
     "iopub.status.busy": "2023-10-13T14:23:22.895699Z",
     "iopub.status.idle": "2023-10-13T14:23:22.901420Z",
     "shell.execute_reply": "2023-10-13T14:23:22.900391Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.013993,
     "end_time": "2023-10-13T14:23:22.903028",
     "exception": false,
     "start_time": "2023-10-13T14:23:22.889035",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, X, y=None, time_steps=1):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.time_steps = time_steps\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X) - self.time_steps\n",
    "\n",
    "    def __getitem__(self, idx): # compatible for both train, test and inferencing\n",
    "        X_sample = self.X[idx:idx+self.time_steps]\n",
    "        if self.y is not None:\n",
    "            y_sample = self.y[idx:idx+self.time_steps]\n",
    "            return X_sample, y_sample\n",
    "        else:\n",
    "            return X_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be494935",
   "metadata": {
    "papermill": {
     "duration": 0.005641,
     "end_time": "2023-10-13T14:23:22.914608",
     "exception": false,
     "start_time": "2023-10-13T14:23:22.908967",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Section 3: Train Model\n",
    "\n",
    "> TODO: Hyperparameters Tuning (CV),\n",
    "Optimizer,\n",
    "Loss Function,\n",
    "Learning Rate Scheduler,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa46068",
   "metadata": {
    "papermill": {
     "duration": 0.005683,
     "end_time": "2023-10-13T14:23:22.926544",
     "exception": false,
     "start_time": "2023-10-13T14:23:22.920861",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Section 3a-1: Model Architecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac0c3cf7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T14:23:22.939820Z",
     "iopub.status.busy": "2023-10-13T14:23:22.939522Z",
     "iopub.status.idle": "2023-10-13T14:23:22.953504Z",
     "shell.execute_reply": "2023-10-13T14:23:22.952547Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.022811,
     "end_time": "2023-10-13T14:23:22.955166",
     "exception": false,
     "start_time": "2023-10-13T14:23:22.932355",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.wq = nn.Linear(d_model, d_model)\n",
    "        self.wk = nn.Linear(d_model, d_model)\n",
    "        self.wv = nn.Linear(d_model, d_model)\n",
    "\n",
    "        self.fc = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        x = x.view(batch_size, -1, self.num_heads, self.depth)\n",
    "        return x.permute(2, 0, 1, 3)\n",
    "\n",
    "    def forward(self, query, key, value):\n",
    "        batch_size = query.size(0)\n",
    "        query = self.split_heads(self.wq(query), batch_size)\n",
    "        key = self.split_heads(self.wk(key), batch_size)\n",
    "        value = self.split_heads(self.wv(value), batch_size)\n",
    "\n",
    "        matmul_qk = torch.matmul(query, key.permute(0, 1, 3, 2))\n",
    "        d_k = key.size(-1)\n",
    "        scaled_attention_logits = matmul_qk / d_k**0.5\n",
    "        attention_weights = torch.nn.functional.softmax(scaled_attention_logits, dim=-1)\n",
    "        output = torch.matmul(attention_weights, value)\n",
    "        output = output.permute(1, 2, 0, 3).contiguous().view(batch_size, -1, self.d_model)\n",
    "        return self.fc(output)\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_model, d_model)\n",
    "        )\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        attn_output = self.mha(x, x, x)\n",
    "        out1 = self.norm1(x + attn_output)\n",
    "        fc_output = self.fc(out1)\n",
    "        return self.norm2(out1 + fc_output)\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_model, d_model)\n",
    "        )\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x, enc_output):\n",
    "        attn1 = self.mha1(x, x, x)\n",
    "        out1 = self.norm1(attn1 + x)\n",
    "        attn2 = self.mha2(out1, enc_output, enc_output)\n",
    "        out2 = self.norm2(attn2 + out1)\n",
    "        fc_output = self.fc(out2)\n",
    "        return self.norm3(fc_output + out2)\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, num_layers, d_model, num_heads, input_seq_len, output_seq_len, num_variables):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.encoder_layers = nn.ModuleList([EncoderLayer(d_model, num_heads) for _ in range(num_layers)])\n",
    "        self.decoder_layers = nn.ModuleList([DecoderLayer(d_model, num_heads) for _ in range(num_layers)])\n",
    "\n",
    "        self.fc_in = nn.Linear(num_variables, d_model)\n",
    "        self.fc_out = nn.Linear(d_model, 1)\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        src = self.fc_in(src)\n",
    "        tgt = self.fc_in(tgt)\n",
    "\n",
    "        for layer in self.encoder_layers:\n",
    "            src = layer(src)\n",
    "\n",
    "        for layer in self.decoder_layers:\n",
    "            tgt = layer(tgt, src)\n",
    "\n",
    "        return self.fc_out(tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "265b0df8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T14:23:22.968466Z",
     "iopub.status.busy": "2023-10-13T14:23:22.967796Z",
     "iopub.status.idle": "2023-10-13T14:23:26.626000Z",
     "shell.execute_reply": "2023-10-13T14:23:26.624858Z"
    },
    "papermill": {
     "duration": 3.667275,
     "end_time": "2023-10-13T14:23:26.628405",
     "exception": false,
     "start_time": "2023-10-13T14:23:22.961130",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ready DataSet from X, y\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # determined the device\n",
    "display(device)\n",
    "X_tensor = torch.tensor(X.values, dtype=torch.float32).to(device) \n",
    "y_tensor = torch.tensor(y, dtype=torch.float32).to(device)\n",
    "# Create Dataset and DataLoader\n",
    "batch_size = 512\n",
    "time_steps = 50\n",
    "dataset = TimeSeriesDataset(X_tensor, y_tensor, time_steps)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d186301",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T14:23:26.644816Z",
     "iopub.status.busy": "2023-10-13T14:23:26.644185Z",
     "iopub.status.idle": "2023-10-13T14:23:26.688437Z",
     "shell.execute_reply": "2023-10-13T14:23:26.687167Z"
    },
    "papermill": {
     "duration": 0.05471,
     "end_time": "2023-10-13T14:23:26.690400",
     "exception": false,
     "start_time": "2023-10-13T14:23:26.635690",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.48 ms, sys: 2.14 ms, total: 11.6 ms\n",
      "Wall time: 36.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Transformer\n",
    "input_seq_len = time_steps\n",
    "output_seq_len = time_steps\n",
    "d_model = 64\n",
    "num_heads = 4\n",
    "num_layers = 2\n",
    "num_variables = X.shape[1]\n",
    "\n",
    "model = Transformer(\n",
    "    num_layers, d_model, num_heads, input_seq_len, output_seq_len, num_variables\n",
    ").to(device)\n",
    "\n",
    "criterion = torch.nn.L1Loss()  \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8675980",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T14:23:26.706450Z",
     "iopub.status.busy": "2023-10-13T14:23:26.705496Z",
     "iopub.status.idle": "2023-10-13T14:23:26.710251Z",
     "shell.execute_reply": "2023-10-13T14:23:26.709390Z"
    },
    "papermill": {
     "duration": 0.014293,
     "end_time": "2023-10-13T14:23:26.712049",
     "exception": false,
     "start_time": "2023-10-13T14:23:26.697756",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "IS_TRAIN = False # set it to train model or load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42705464",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T14:23:26.727479Z",
     "iopub.status.busy": "2023-10-13T14:23:26.726609Z",
     "iopub.status.idle": "2023-10-13T14:23:26.764012Z",
     "shell.execute_reply": "2023-10-13T14:23:26.763085Z"
    },
    "papermill": {
     "duration": 0.046856,
     "end_time": "2023-10-13T14:23:26.765864",
     "exception": false,
     "start_time": "2023-10-13T14:23:26.719008",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.1 ms, sys: 1.89 ms, total: 12 ms\n",
      "Wall time: 28.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if IS_TRAIN:\n",
    "    num_epochs = 5\n",
    "    print_every_n_batches = 10  # Adjust this to your preference\n",
    "\n",
    "    # Training loop\n",
    "    model.train()\n",
    "    losses = []\n",
    "    # accuracies = []\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_losses = []\n",
    "    #     epoch_accuracies = []\n",
    "        for i, (batch_X, batch_y) in enumerate(dataloader):\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            outputs = model(batch_X, batch_X) \n",
    "            outputs = outputs.squeeze(-1)  # Remove the last dimension of size 1\n",
    "            loss = criterion(outputs, batch_y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_losses.append(loss.item())\n",
    "            # Print loss every n batches\n",
    "            if (i + 1) % print_every_n_batches == 0:\n",
    "                sys.stdout.write('\\r' + f\"Epoch {epoch+1}/{num_epochs}, Batch {i+1}/{len(dataloader)}, Loss: {loss.item()}\")\n",
    "                sys.stdout.flush()\n",
    "\n",
    "\n",
    "        print(f\"\\n => Epoch {epoch+1}/{num_epochs}, Loss: {np.mean(epoch_losses)}\")\n",
    "        losses.append(np.mean(epoch_losses))\n",
    "    \n",
    "    print(losses)\n",
    "else:\n",
    "    model_save_path = \"/kaggle/input/finance-transformer-1/transformer_model.pth\"\n",
    "    model.load_state_dict(torch.load(model_save_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f64aaf",
   "metadata": {
    "papermill": {
     "duration": 0.00579,
     "end_time": "2023-10-13T14:23:26.778026",
     "exception": false,
     "start_time": "2023-10-13T14:23:26.772236",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    ">Epoch 1/5, Batch 10230/10231, Loss: 3.8339190483093263\n",
    " => Epoch 1/5, Loss: 6.410258663887968\n",
    "Epoch 2/5, Batch 10230/10231, Loss: 3.8925738334655761\n",
    " => Epoch 2/5, Loss: 6.410010247341921\n",
    "Epoch 3/5, Batch 10230/10231, Loss: 3.8768408298492435\n",
    " => Epoch 3/5, Loss: 6.4099562952984765\n",
    "Epoch 4/5, Batch 10230/10231, Loss: 3.8611757755279544\n",
    " => Epoch 4/5, Loss: 6.410132407978965\n",
    "Epoch 5/5, Batch 10230/10231, Loss: 3.9083080291748047\n",
    " => Epoch 5/5, Loss: 6.4099540124831105\n",
    "[6.410258663887968, 6.410010247341921, 6.4099562952984765, 6.410132407978965, 6.4099540124831105]\n",
    "CPU times: user 31min 5s, sys: 5.43 s, total: 31min 11s\n",
    "Wall time: 31min 17s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6ee506",
   "metadata": {
    "papermill": {
     "duration": 0.005713,
     "end_time": "2023-10-13T14:23:26.789698",
     "exception": false,
     "start_time": "2023-10-13T14:23:26.783985",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Save Model: Training in GPU is expensive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e1c35c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T14:23:26.846314Z",
     "iopub.status.busy": "2023-10-13T14:23:26.845345Z",
     "iopub.status.idle": "2023-10-13T14:23:26.850133Z",
     "shell.execute_reply": "2023-10-13T14:23:26.849323Z"
    },
    "papermill": {
     "duration": 0.013758,
     "end_time": "2023-10-13T14:23:26.851795",
     "exception": false,
     "start_time": "2023-10-13T14:23:26.838037",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if IS_TRAIN:\n",
    "    model_save_path = \"transformer_model.pth\"\n",
    "    torch.save(model.state_dict(), model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fc1ced",
   "metadata": {
    "papermill": {
     "duration": 0.005821,
     "end_time": "2023-10-13T14:23:26.863574",
     "exception": false,
     "start_time": "2023-10-13T14:23:26.857753",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Section 3a: Inspect Model\n",
    "> TODO: Inspect Training results ( Overfit/underfit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45edd064",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T14:23:26.877287Z",
     "iopub.status.busy": "2023-10-13T14:23:26.876463Z",
     "iopub.status.idle": "2023-10-13T14:23:26.882952Z",
     "shell.execute_reply": "2023-10-13T14:23:26.882031Z"
    },
    "papermill": {
     "duration": 0.015097,
     "end_time": "2023-10-13T14:23:26.884641",
     "exception": false,
     "start_time": "2023-10-13T14:23:26.869544",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (encoder_layers): ModuleList(\n",
       "    (0-1): 2 x EncoderLayer(\n",
       "      (mha): MultiHeadAttention(\n",
       "        (wq): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (wk): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (wv): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (fc): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (fc): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (decoder_layers): ModuleList(\n",
       "    (0-1): 2 x DecoderLayer(\n",
       "      (mha1): MultiHeadAttention(\n",
       "        (wq): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (wk): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (wv): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (fc): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (mha2): MultiHeadAttention(\n",
       "        (wq): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (wk): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (wv): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (fc): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (fc): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm3): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (fc_in): Linear(in_features=13, out_features=64, bias=True)\n",
       "  (fc_out): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0efec51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T14:23:26.898648Z",
     "iopub.status.busy": "2023-10-13T14:23:26.897784Z",
     "iopub.status.idle": "2023-10-13T14:23:26.906157Z",
     "shell.execute_reply": "2023-10-13T14:23:26.905167Z"
    },
    "papermill": {
     "duration": 0.016989,
     "end_time": "2023-10-13T14:23:26.907841",
     "exception": false,
     "start_time": "2023-10-13T14:23:26.890852",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135361"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "135361"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
    "pytorch_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "display(pytorch_total_params)\n",
    "display(pytorch_trainable_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc24d1fc",
   "metadata": {
    "papermill": {
     "duration": 0.006084,
     "end_time": "2023-10-13T14:23:26.920146",
     "exception": false,
     "start_time": "2023-10-13T14:23:26.914062",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Section 3b: Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2063dfd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T14:23:26.934177Z",
     "iopub.status.busy": "2023-10-13T14:23:26.933408Z",
     "iopub.status.idle": "2023-10-13T14:23:47.772797Z",
     "shell.execute_reply": "2023-10-13T14:23:47.771788Z"
    },
    "papermill": {
     "duration": 20.848408,
     "end_time": "2023-10-13T14:23:47.774756",
     "exception": false,
     "start_time": "2023-10-13T14:23:26.926348",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 0.49637895822525024 0.0\n",
      "200 0.4963789615035057 1.3588682550404067e-08\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637896060943604 1.1680077279964341e-08\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.4963789728283882 2.5635194805893768e-08\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.4963789653778076 1.93692169299983e-08\n",
      "200 0.4963789623975754 1.520794728061327e-08\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637897312641144 2.5809568279517847e-08\n",
      "200 0.4963789615035057 1.3588682550404067e-08\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.4963789594173431 8.344650268554688e-09\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.4963789668679237 2.098684536392481e-08\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.4963789594173431 8.344650268554687e-09\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.4963789591193199 7.24509106942607e-09\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.4963789594173431 8.344650268554688e-09\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.4963789591193199 7.245091069426071e-09\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637896060943604 1.1680077279964343e-08\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.4963789594173431 8.344650268554687e-09\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.4963789764046669 2.744242121358347e-08\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.4963789591193199 7.24509106942607e-09\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.496378967165947 2.1283115233608633e-08\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.496378967165947 2.1283115233608633e-08\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637897312641144 2.5809568279517847e-08\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.4963789618015289 1.4155318840787312e-08\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.4963789650797844 1.9015189577280604e-08\n",
      "200 0.49637896329164505 1.662264438555758e-08\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.496378967165947 2.1283115233608633e-08\n",
      "200 0.49637896120548247 1.2990531157078364e-08\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637896090745925 1.2356288696305682e-08\n",
      "200 0.4963789588212967 5.930587274471641e-09\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.4963789728283882 2.5635194805893768e-08\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.4963789591193199 7.245091069426071e-09\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637896835803985 2.2389459575406253e-08\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.4963789597153664 9.305772182939048e-09\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637896597385406 2.0045246745109844e-08\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.4963789623975754 1.520794728061327e-08\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637896597385406 2.0045246745109847e-08\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.4963789728283882 2.5635194805893768e-08\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637896835803985 2.2389459575406253e-08\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.4963789638876915 1.747697223591298e-08\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895852327346 4.204134935041035e-09\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n"
     ]
    }
   ],
   "source": [
    "def test_iterator(df, test_size=200):\n",
    "    \"\"\"Yields batches of rows from the dataframe.\"\"\"\n",
    "    num_batches = len(df) // test_size + (1 if len(df) % test_size else 0)\n",
    "    \n",
    "    for i in range(num_batches):\n",
    "        start_idx = i * test_size\n",
    "        end_idx = start_idx + test_size\n",
    "        yield df[start_idx:end_idx]\n",
    "\n",
    "# inference helper\n",
    "def inference_model_from_df(df, m):\n",
    "    test_df = t\n",
    "    feat = feat_eng(test_df)\n",
    "    feat = feat.fillna(1)\n",
    "    feat = (feat - mean) / std # normalize\n",
    "    \n",
    "    # Convert to tensor and move to device\n",
    "    feat_tensor = torch.tensor(feat.values, dtype=torch.float32).to(device)\n",
    "    \n",
    "    # Ensure you're in eval mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Initialize the full predictions list to store the entire sequence of predictions\n",
    "    full_predictions = []\n",
    "    \n",
    "    # Predict the 20 future steps for every `time_steps` chunk\n",
    "    for start_idx in range(0, len(test_df) - time_steps + 1, 20):\n",
    "        sequence = feat_tensor[start_idx:start_idx+time_steps].unsqueeze(0)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            predictions = model(sequence, sequence).squeeze().cpu().numpy()\n",
    "            \n",
    "            # Add the predicted values to the full_predictions list\n",
    "            extra = len(full_predictions) + len(predictions) - len(test_df)\n",
    "            if extra > 0:\n",
    "                predictions = predictions[extra:]\n",
    "            full_predictions.extend(predictions.tolist())\n",
    "\n",
    "    \n",
    "    # Make sure the predictions size matches the size of sample_prediction\n",
    "    assert len(full_predictions) == len(t), \"Mismatch between prediction size and expected size\"\n",
    "    print(len(full_predictions), np.mean(full_predictions), np.std(full_predictions))\n",
    "    return full_predictions\n",
    "    \n",
    "test_df_iterator = test_iterator(test, test_size=200)\n",
    "for t in test_df_iterator:\n",
    "    full_predictions = inference_model_from_df(df=t, m=model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7efc692",
   "metadata": {
    "papermill": {
     "duration": 0.008612,
     "end_time": "2023-10-13T14:23:47.792955",
     "exception": false,
     "start_time": "2023-10-13T14:23:47.784343",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Section 4: Inference Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94250cdb",
   "metadata": {
    "papermill": {
     "duration": 0.008627,
     "end_time": "2023-10-13T14:23:47.810225",
     "exception": false,
     "start_time": "2023-10-13T14:23:47.801598",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Section 4a: Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85f4fe3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T14:23:47.829354Z",
     "iopub.status.busy": "2023-10-13T14:23:47.828731Z",
     "iopub.status.idle": "2023-10-13T14:23:47.833537Z",
     "shell.execute_reply": "2023-10-13T14:23:47.832955Z"
    },
    "papermill": {
     "duration": 0.016063,
     "end_time": "2023-10-13T14:23:47.835033",
     "exception": false,
     "start_time": "2023-10-13T14:23:47.818970",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def zero_sum(prices, volumes): \n",
    "#    I got this idea from https://github.com/gotoConversion/goto_conversion/\n",
    "    std_error = np.sqrt(volumes)\n",
    "    step = np.sum(prices)/np.sum(std_error)\n",
    "    out = prices-std_error*step\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7cdaeb99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T14:23:47.854010Z",
     "iopub.status.busy": "2023-10-13T14:23:47.853228Z",
     "iopub.status.idle": "2023-10-13T14:23:47.879786Z",
     "shell.execute_reply": "2023-10-13T14:23:47.878930Z"
    },
    "papermill": {
     "duration": 0.037949,
     "end_time": "2023-10-13T14:23:47.881612",
     "exception": false,
     "start_time": "2023-10-13T14:23:47.843663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import optiver2023\n",
    "env = optiver2023.make_env()\n",
    "iter_test = env.iter_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2d1a6ac3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T14:23:47.901702Z",
     "iopub.status.busy": "2023-10-13T14:23:47.900929Z",
     "iopub.status.idle": "2023-10-13T14:24:08.712595Z",
     "shell.execute_reply": "2023-10-13T14:24:08.711599Z"
    },
    "papermill": {
     "duration": 20.823239,
     "end_time": "2023-10-13T14:24:08.714467",
     "exception": false,
     "start_time": "2023-10-13T14:23:47.891228",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This version of the API is not optimized and should not be used to estimate the runtime of your code on the hidden test set.\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n",
      "200 0.49637895822525024 0.0\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for (test_df, revealed_targets, sample_prediction) in iter_test:\n",
    "    full_predictions = inference_model_from_df(df=test_df, m=model)\n",
    "    \n",
    "    # Fill the 'target' field with the model's outputs\n",
    "    sample_prediction['target'] = full_predictions\n",
    "    \n",
    "    # Apply any other necessary post-processing\n",
    "    sample_prediction['target'] = zero_sum(sample_prediction['target'], test_df.loc[:, 'bid_size'] + test_df.loc[:, 'ask_size'])\n",
    "    \n",
    "    env.predict(sample_prediction)\n",
    "    counter += 1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ceaf79",
   "metadata": {
    "papermill": {
     "duration": 0.011534,
     "end_time": "2023-10-13T14:24:08.738295",
     "exception": false,
     "start_time": "2023-10-13T14:24:08.726761",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 74.21128,
   "end_time": "2023-10-13T14:24:10.272820",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-10-13T14:22:56.061540",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
